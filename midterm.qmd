---
title: "BSMM-midterm"
subtitle: "BSMM 8740 Fall 2023"
author: "Add your name here"
date: "Add the date here"
editor: visual
format: html
self-contained: true
---

# Instructions

::: callout-important
To access Github from the lab, you will need to make sure you are logged in as follows:

-   username: **.\\daladmin**
-   password: **Business507!**

Remember to

-   create your PAT using `usethis::create_github_token()` ,
-   store your PAT with `gitcreds::gitcreds_set()` ,
-   set your username and email with
    -   `usethis::use_git_config( user.name = ___, user.email = ___)`
:::

## Overview

The midterm will be released on Monday, October 30, and is designed to be completed in 60+ minutes.

The exam will consist of two parts:

1.  **Part 1 - Conceptual:** Simple questions designed to evaluate your familiarity with the written course notes.
2.  **Part 2 - Applied:** Data analysis in RStudio (like a usual lab, but simpler).

Log in to *your* github account and then go to the [GitHub organization](https://github.com/bsmm-8740-fall-2023) for the course and find the **BSMM-midterm-\[your github username\]** repository to complete the exam.

Create an R project using your `midterm` repository (remember to create a PAT, etc., as in lab-1) and add your answers by editing the `midterm.qmd` file in your repository. Your first edits should be to the date and your name (as author) at the top of this document.

Be sure that you have saved, staged, committed, and pushed your work before the end of the exam.

üçÄ Good luck! üçÄ

## Academic Integrity

By taking this exam, you pledge to that:

-   I will not lie, cheat, or steal in my academic endeavors;

-   I will conduct myself honorably in all my endeavors; and

-   I will act if the Standard is compromised.

## Rules & Notes

-   This is an individual assignment. Everything in your repository is for your eyes only.

-   You may not collaborate or communicate anything about this exam to **anyone** except the instructor. For example, you may not communicate with other students or post/solicit help on the internet, email or via any other method of communication.

-   The exam is open-book, open-note, so you may use any materials from class as you take the exam.

## Submission

-   Your answers should be typed in the document below (or answer by deleting alternative answers in multiple choice questions.

-   Make sure you commit any changes and push the changes to the course repository before the end of the quiz.

-   Once the quiz has ended, the contents of your repository will be pulled for grading. This will happen only once, so no changes made after the end of the quiz will be recorded.

------------------------------------------------------------------------

# Quiz-1 (part 1)

## Q-1

Is this data a `tidy` dataset?

| Region    | \< \$1M | \$1 - \$5M | \$5 - \$10M | \$10 - \$100M | \> \$100M |
|-----------|---------|------------|-------------|---------------|-----------|
| N America | \$50M   | \$324M     | \$1045M     | \$941M        | \$1200M   |
| EMEA      | \$10M   | \$121M     | \$77M       | \$80M         | \$0M      |

*Delete the wrong answer:*

-   Yes
-   No

## Q-2

Which `dlpyr::` function possibly reduces the number of rows in a dataset? *Delete the wrong answers below*.

-   **dplyr::select()**
-   **dplyr::arrange()**
-   **dplyr::filter**

## Q-3

If I join the *two* tables below as follows:

``` r
dplyr::????_join(employees, departments, by = "department_id")
```

which type of join would include a row with **employee_name == Moe Syzslak**?

-   inner
-   left
-   right
-   all of the above

*Delete the incorrect answers*.

**employees** - This table contains each employee's ID, name, and department ID.

| id  | employee_name | department_id |
|-----|---------------|---------------|
| 1   | Homer Simpson | 4             |
| 2   | Ned Flanders  | 1             |
| 3   | Barney Gumble | 5             |
| 4   | Clancy Wiggum | 3             |
| 5   | Moe Syzslak   | NA            |

**departments** - This table contains each department's ID and name.

| department_id | department_name          |
|---------------|--------------------------|
| 1             | Sales                    |
| 2             | Engineering              |
| 3             | Human Resources          |
| 4             | Customer Service         |
| 5             | Research And Development |

## Q-4

Give two questions you might ask of the data during exploratory data analysis.

1.  \_\_\_

2.  \_\_\_

## Q-5

If you thought your data had seasonality, what type of feature might you add to your predictive variables?

1.  lag variables
2.  basis functions
3.  date-part variables
4.  all of the above (1,2,3)
5.  none of the above (1,2,3)

*Delete the incorrect answers*.

# Quiz-1 (part 2)

## Q6

Execute the following code to read sales data from a csv file and answer the questions about the code below.

```{r}
#| echo: true
#| message: false
#| error: false

require(magrittr)
require(ggplot2)

# read sales data
sales_dat <-
  readr::read_csv("data/sales_data_sample.csv", show_col_types = FALSE) %>%
  janitor::clean_names() %>% 
  dplyr::mutate(
    orderdate = lubridate::as_date(orderdate, format = "%m/%d/%Y %H:%M")
    , orderdate = lubridate::year(orderdate)
  )

```

::: {.callout-note appearance="simple" icon="false"}
## SOLUTION :

-   the result of the **`clean_names`** step is:
-   the result of the **`mutate`** step is:
:::

## Q7

Using the sales data that was loaded in the last question, describe what the `group_by` step does in the code below, and complete the code to produce a sales summary by year. Execute your code to confirm that it is doing what you expect.

```{r}
#| eval: false
  sales_dat %>% 
    dplyr::group_by(orderdate, productline) %>% 
    dplyr::summarize( sales = sum(___) ) %>% 
    tidyr::pivot_wider(names_from = ___, values_from = ___)
```

::: {.callout-note appearance="simple" icon="false"}
## SOLUTION :

-   the result of the **`group_by`** step is:

-   the sales summary table produced by the code is given below

```{r}
# executed code

```
:::

## Q8

Execute the following code to read salary data from a csv file and perform the following analyses.

-   code an ordinary linear regression to estimate the best linear relationship between monthly salary (the outcome, in \$000's) and months of experience.
-   extract the residuals from the fit object( using fit\$residuals) and show the qqplot (using `qqnorm`) for the residuals.
-   which assumption of ordinary linear regression does the qqplot validate.
-   is the assumption satisfied in this case?

```{r}
#| echo: true
salary_dat <-
  readr::read_csv("data/Experience-Salary.csv", show_col_types = FALSE) %>%
  janitor::clean_names()
```

::: {.callout-note appearance="simple" icon="false"}
## SOLUTION:

```{r}

```
:::

## Q9

Execute the following code to read student performance data from a csv file and code the following analyses where the outcome/target variable is **performance_index**, and all other columns are predictors.

-   use `rsample::initial_split` to create training and test datasets, and extract the training and test datasets using the corresponding `rsample::?` functions
-   use `recipes::recipe` to preprocess the data by normalizing the numeric predictors and creating dummy variables for the nominal predictors
-   prep the recipe you created and then use it with recipes::bake applied to the **training** dataset to create a analysis dataset.
-   run an ordinary linear regression to predict **performance_index** from the predictors, using the analysis dataset. Save the fit object.
-   use `broom::augment` (fit, data) to combine your linear fit with the corresponding training data. This step gives a tibble with a `.resid` column that is the difference between the prediction and the observed value.
-   use the .resid column to calculate the mean squared error (mse) of the fit to the training data.

```{r}
#| echo: true
#| eval: false
performance_dat <-
  readr::read_csv("data/Student_Performance.csv", show_col_types = FALSE) %>%
  janitor::clean_names()

```

::: {.callout-note appearance="simple" icon="false"}
## SOLUTION:

```{r}
#| eval: false
splits <- rsample::initial_split(performance_dat)
training <- ?
testing <- ?

 rec <- recipes::recipe(performance_index ~ .) %>% 
  recipes::step_ ?  %>% 
  recipes::setp_ ?
  
performance_fit <- lm(performance_index ~ .,
   data = ?)  

result <- broom::augment(?,?)

result %>% 
  dplyr::mutate( mse = ?)
```
:::

## Q10

Execute the following code to read employee absence data from a xls file and create a recipe to preprocess the data. Do the following:

-   familiarize yourself with the data using `skimr::skim()` ,
-   describe what each step of the recipe is doing,
-   split the data into training and test sets, where the training set represents 80% of the data (the default is 75%).
-   add the missing arguments to the code that trains an xgboost model. You will need to prep the recipe & bake the prepped recipe. Finally you will need to ensure your argument is a matrix, by using `as.matrix()` .
-   pull the top 10 predictors from the model using `xgboost::xgb.importance(model = ., top_n = 10)`
-   finally, plot the top 10 predictors. What it the most important predictor of absenteeism time per this model?

```{r}
#| eval: false
dat <-
  readxl::read_xls("data/Absenteeism_at_work.xls") %>%
  janitor::clean_names() %>%
  # drop id, because it has no predictive value
  # drop reason_for_absence because it has too much predictive value
  dplyr::select( -c(id, reason_for_absence) )

absenteeism_rec <- dat %>%
  recipes::recipe(absenteeism_time_in_hours ~ .) %>%
  recipes::step_mutate(
    month_of_absence   = ifelse(month_of_absence>0, month.name[month_of_absence], "unknown")
    , day_of_the_week  = lubridate::wday(day_of_the_week, label=T)
    , seasons          = dplyr::case_when(
                            seasons==1 ~ 'winter',seasons==2 ~ 'spring'
                            ,seasons==3 ~ 'summer',seasons==4 ~ 'fall'
                          )
    , social_drinker   = dplyr::case_when(social_drinker>0 ~ "Yes", TRUE ~ "No")
    , social_smoker    = dplyr::case_when(social_smoker>0 ~ "Yes", TRUE ~ "No")
    , disciplinary_failure = dplyr::case_when(disciplinary_failure>0 ~ "Yes", TRUE ~ "No")
  ) %>%
  recipes::step_string2factor(where(is.character)) %>%
  recipes::step_normalize(recipes::all_numeric_predictors()) %>%
  recipes::step_dummy(recipes::all_nominal_predictors())

untuned_xgb <-
  xgboost::xgboost(
    data = ?,
    label = ?,
    nrounds = 1000,
    objective = "reg:squarederror",
    early_stopping_rounds = 3,
    max_depth = 6,
    eta = .25
    , verbose = FALSE
  )
```

::: {.callout-note appearance="simple" icon="false"}
## SOLUTION:

```{r}
# your code goes here
```
:::

# Grading (20 pts)

| **Part**                | **Points** |
|:------------------------|:----------:|
| **Part 1 - Conceptual** |     10     |
| **Part 2 - Applied**    |     10     |
| **Total**               |     20     |
